"""
Library Detector for Library Vulnerability Scanner

This module contains the core library detection logic using multiple
detection methods including gradle analysis, binary inspection,
source code analysis, and manifest analysis.

Features:
- Multi-method library detection (gradle, binary, source, manifest)
- Pattern-based library identification
- Version extraction and validation
- Confidence scoring for detections
- Performance-optimized analysis
"""

import logging
import os
import re
import subprocess
import zipfile
import hashlib
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional, Any
import xml.etree.ElementTree as ET

from .data_structures import (
    LibraryInfo, DetectionMethod, LibraryType, LibraryAnalysisConfig
)

logger = logging.getLogger(__name__)

class LibraryDetector:
    """Comprehensive library detector using multiple detection methods."""
    
    def __init__(self, apk_ctx, config: LibraryAnalysisConfig):
        """Initialize the library detector."""
        self.apk_ctx = apk_ctx
        self.config = config
        self.package_name = apk_ctx.package_name
        self.apk_path = apk_ctx.apk_path
        
        # Initialize detection patterns
        self._initialize_detection_patterns()
        
        # Results storage
        self.detected_libraries: List[LibraryInfo] = []
        self.detection_cache: Dict[str, Any] = {}
    
    def _initialize_detection_patterns(self) -> None:
        """Initialize comprehensive library detection patterns."""
        self.library_patterns = {
            # OpenSSL Detection Patterns
            "openssl": {
                "gradle_patterns": [
                    r'implementation\s+["\'].*openssl.*["\']\s*:\s*["\']([^"\']+)["\']',
                    r'compile\s+["\'].*openssl.*["\']\s*:\s*["\']([^"\']+)["\']',
                    r'api\s+["\'].*openssl.*["\']\s*:\s*["\']([^"\']+)["\']'
                ],
                "binary_patterns": [
                    r'libssl\.so',
                    r'libcrypto\.so',
                    r'OpenSSL\s+([0-9]+\.[0-9]+\.[0-9]+[a-z]?)',
                    r'OPENSSL_VERSION_TEXT.*"([^"]+)"'
                ],
                "source_patterns": [
                    r'import.*openssl',
                    r'#include\s*[<"]openssl/',
                    r'SSL_library_init',
                    r'OpenSSL_add_all_algorithms'
                ],
                "library_type": LibraryType.CRYPTOGRAPHIC,
                "vendor": "OpenSSL Software Foundation"
            },
            
            # OkHTTP Detection Patterns
            "okhttp": {
                "gradle_patterns": [
                    r'implementation\s+["\']com\.squareup\.okhttp3?:okhttp:([^"\']+)["\']',
                    r'compile\s+["\']com\.squareup\.okhttp3?:okhttp:([^"\']+)["\']',
                    r'api\s+["\']com\.squareup\.okhttp3?:okhttp:([^"\']+)["\']',
                    r'com\.squareup\.okhttp3?\s*:\s*okhttp\s*:\s*([0-9\.]+)'
                ],
                "manifest_patterns": [
                    r'okhttp3?\.jar',
                    r'okhttp-([0-9\.]+)\.jar'
                ],
                "source_patterns": [
                    r'import\s+okhttp3?\.',
                    r'import\s+com\.squareup\.okhttp3?\.',
                    r'OkHttpClient',
                    r'Request\.Builder',
                    r'Response\.body'
                ],
                "library_type": LibraryType.NETWORKING,
                "vendor": "Square Inc."
            },
            
            # libjpeg-turbo Detection Patterns
            "libjpeg_turbo": {
                "binary_patterns": [
                    r'libjpeg-turbo\s+([0-9]+\.[0-9]+\.[0-9]+)',
                    r'libturbojpeg\.so',
                    r'tjCompress2',
                    r'tjDecompress2'
                ],
                "source_patterns": [
                    r'#include\s*[<"]turbojpeg\.h[">]',
                    r'tjInitCompress',
                    r'tjInitDecompress'
                ],
                "library_type": LibraryType.IMAGE_PROCESSING,
                "vendor": "libjpeg-turbo Project"
            },
            
            # libpng Detection Patterns
            "libpng": {
                "binary_patterns": [
                    r'libpng([0-9]+)\.so',
                    r'PNG\s+([0-9]+\.[0-9]+\.[0-9]+)',
                    r'png_create_read_struct'
                ],
                "source_patterns": [
                    r'#include\s*[<"]png\.h[">]',
                    r'png_read_png',
                    r'png_write_png'
                ],
                "library_type": LibraryType.IMAGE_PROCESSING,
                "vendor": "PNG Development Group"
            },
            
            # Joda Time Detection Patterns
            "joda_time": {
                "gradle_patterns": [
                    r'implementation\s+["\']joda-time:joda-time:([^"\']+)["\']',
                    r'compile\s+["\']joda-time:joda-time:([^"\']+)["\']'
                ],
                "source_patterns": [
                    r'import\s+org\.joda\.time\.',
                    r'DateTime',
                    r'LocalDateTime'
                ],
                "library_type": LibraryType.UTILITY,
                "vendor": "Joda.org"
            },
            
            # Jackson Databind Detection Patterns
            "jackson_databind": {
                "gradle_patterns": [
                    r'implementation\s+["\']com\.fasterxml\.jackson\.core:jackson-databind:([^"\']+)["\']',
                    r'compile\s+["\']com\.fasterxml\.jackson\.core:jackson-databind:([^"\']+)["\']'
                ],
                "source_patterns": [
                    r'import\s+com\.fasterxml\.jackson\.',
                    r'ObjectMapper',
                    r'JsonNode'
                ],
                "library_type": LibraryType.UTILITY,
                "vendor": "FasterXML"
            },
            
            # Retrofit Detection Patterns
            "retrofit": {
                "gradle_patterns": [
                    r'implementation\s+["\']com\.squareup\.retrofit2?:retrofit:([^"\']+)["\']',
                    r'compile\s+["\']com\.squareup\.retrofit2?:retrofit:([^"\']+)["\']'
                ],
                "source_patterns": [
                    r'import\s+retrofit2?\.',
                    r'@GET',
                    r'@POST',
                    r'Retrofit\.Builder'
                ],
                "library_type": LibraryType.NETWORKING,
                "vendor": "Square Inc."
            },
            
            # Gson Detection Patterns
            "gson": {
                "gradle_patterns": [
                    r'implementation\s+["\']com\.google\.code\.gson:gson:([^"\']+)["\']',
                    r'compile\s+["\']com\.google\.code\.gson:gson:([^"\']+)["\']'
                ],
                "source_patterns": [
                    r'import\s+com\.google\.gson\.',
                    r'Gson',
                    r'JsonObject'
                ],
                "library_type": LibraryType.UTILITY,
                "vendor": "Google"
            }
        }
    
    def detect_libraries(self) -> List[LibraryInfo]:
        """Perform comprehensive library detection using all available methods."""
        logger.info("Starting comprehensive library detection")
        
        try:
            self.detected_libraries.clear()
            
            # Method 1: Gradle dependency analysis
            if self.config.enable_gradle_analysis:
                self._analyze_gradle_dependencies()
            
            # Method 2: Binary analysis
            if self.config.enable_binary_analysis:
                self._analyze_native_libraries()
            
            # Method 3: Source code analysis
            if self.config.enable_source_analysis:
                self._analyze_source_imports()
            
            # Method 4: Manifest analysis
            if self.config.enable_manifest_analysis:
                self._analyze_manifest_libraries()
            
            # Remove duplicates and merge detections
            self._deduplicate_detections()
            
            logger.info(f"Library detection completed. Found {len(self.detected_libraries)} libraries")
            return self.detected_libraries
            
        except Exception as e:
            logger.error(f"Library detection failed: {e}")
            return []
    
    def _analyze_gradle_dependencies(self) -> None:
        """Analyze Gradle build files for dependency declarations."""
        logger.debug("Analyzing Gradle dependencies")
        
        try:
            # Extract and analyze build.gradle files
            gradle_files = self._extract_gradle_files()
            
            for gradle_file, content in gradle_files.items():
                self._parse_gradle_content(content, gradle_file)
                
        except Exception as e:
            logger.error(f"Gradle analysis failed: {e}")
    
    def _extract_gradle_files(self) -> Dict[str, str]:
        """Extract Gradle build files from APK."""
        gradle_files = {}
        
        try:
            with zipfile.ZipFile(self.apk_path, 'r') as apk_zip:
                for file_info in apk_zip.filelist:
                    filename = file_info.filename
                    
                    if filename.endswith(('build.gradle', 'build.gradle.kts')):
                        try:
                            content = apk_zip.read(filename).decode('utf-8', errors='ignore')
                            gradle_files[filename] = content
                        except Exception as e:
                            logger.warning(f"Failed to read {filename}: {e}")
            
        except Exception as e:
            logger.error(f"Failed to extract Gradle files: {e}")
        
        return gradle_files
    
    def _parse_gradle_content(self, content: str, file_path: str) -> None:
        """Parse Gradle content for library dependencies."""
        for library_name, patterns in self.library_patterns.items():
            gradle_patterns = patterns.get("gradle_patterns", [])
            
            for pattern in gradle_patterns:
                matches = re.finditer(pattern, content, re.MULTILINE | re.IGNORECASE)
                
                for match in matches:
                    version = match.group(1) if match.groups() else "unknown"
                    
                    library_info = LibraryInfo(
                        name=library_name,
                        version=version,
                        location=file_path,
                        detection_method=DetectionMethod.GRADLE_ANALYSIS,
                        confidence=0.9,  # High confidence for gradle analysis
                        file_path=file_path,
                        library_type=patterns.get("library_type", LibraryType.UTILITY),
                        vendor=patterns.get("vendor", ""),
                        detection_patterns=[pattern],
                        evidence_sources=[f"Gradle dependency: {match.group(0)}"]
                    )
                    
                    self.detected_libraries.append(library_info)
    
    def _analyze_native_libraries(self) -> None:
        """Analyze native libraries (.so files) for library detection."""
        logger.debug("Analyzing native libraries")
        
        try:
            # Extract native libraries from lib/ directory
            native_libs = self._extract_native_libraries()
            
            for lib_path, lib_content in native_libs.items():
                self._analyze_native_library_content(lib_content, lib_path)
                
        except Exception as e:
            logger.error(f"Native library analysis failed: {e}")
    
    def _extract_native_libraries(self) -> Dict[str, bytes]:
        """Extract native libraries from APK."""
        native_libs = {}
        
        try:
            with zipfile.ZipFile(self.apk_path, 'r') as apk_zip:
                for file_info in apk_zip.filelist:
                    filename = file_info.filename
                    
                    if filename.startswith('lib/') and filename.endswith('.so'):
                        try:
                            content = apk_zip.read(filename)
                            native_libs[filename] = content
                        except Exception as e:
                            logger.warning(f"Failed to read {filename}: {e}")
            
        except Exception as e:
            logger.error(f"Failed to extract native libraries: {e}")
        
        return native_libs
    
    def _analyze_native_library_content(self, content: bytes, lib_path: str) -> None:
        """Analyze native library content for library signatures."""
        try:
            # Convert binary content to string for pattern matching
            content_str = content.decode('utf-8', errors='ignore')
            
            for library_name, patterns in self.library_patterns.items():
                binary_patterns = patterns.get("binary_patterns", [])
                
                for pattern in binary_patterns:
                    matches = re.finditer(pattern, content_str, re.MULTILINE | re.IGNORECASE)
                    
                    for match in matches:
                        version = self._extract_version_from_match(match)
                        
                        library_info = LibraryInfo(
                            name=library_name,
                            version=version,
                            location=lib_path,
                            detection_method=DetectionMethod.BINARY_ANALYSIS,
                            confidence=0.8,  # Good confidence for binary analysis
                            file_path=lib_path,
                            checksum=hashlib.md5(content).hexdigest(),
                            file_size=len(content),
                            library_type=patterns.get("library_type", LibraryType.NATIVE),
                            vendor=patterns.get("vendor", ""),
                            detection_patterns=[pattern],
                            evidence_sources=[f"Binary signature: {match.group(0)}"]
                        )
                        
                        self.detected_libraries.append(library_info)
        
        except Exception as e:
            logger.warning(f"Failed to analyze native library {lib_path}: {e}")
    
    def _analyze_source_imports(self) -> None:
        """Analyze source code files for library import statements."""
        logger.debug("Analyzing source imports")
        
        try:
            # Extract and analyze source files
            source_files = self._extract_source_files()
            
            for source_file, content in source_files.items():
                self._parse_source_content(content, source_file)
                
        except Exception as e:
            logger.error(f"Source analysis failed: {e}")
    
    def _extract_source_files(self) -> Dict[str, str]:
        """Extract source files from APK."""
        source_files = {}
        
        try:
            with zipfile.ZipFile(self.apk_path, 'r') as apk_zip:
                for file_info in apk_zip.filelist:
                    filename = file_info.filename
                    
                    # Look for Java, Kotlin, and native source files
                    if filename.endswith(('.java', '.kt', '.cpp', '.c', '.h')):
                        try:
                            content = apk_zip.read(filename).decode('utf-8', errors='ignore')
                            source_files[filename] = content
                        except Exception as e:
                            logger.warning(f"Failed to read {filename}: {e}")
            
        except Exception as e:
            logger.error(f"Failed to extract source files: {e}")
        
        return source_files
    
    def _parse_source_content(self, content: str, file_path: str) -> None:
        """Parse source content for library usage patterns."""
        for library_name, patterns in self.library_patterns.items():
            source_patterns = patterns.get("source_patterns", [])
            
            for pattern in source_patterns:
                matches = re.finditer(pattern, content, re.MULTILINE | re.IGNORECASE)
                
                for match in matches:
                    library_info = LibraryInfo(
                        name=library_name,
                        version="detected",  # Version usually not available in source
                        location=file_path,
                        detection_method=DetectionMethod.SOURCE_ANALYSIS,
                        confidence=0.7,  # Moderate confidence for source analysis
                        file_path=file_path,
                        library_type=patterns.get("library_type", LibraryType.UTILITY),
                        vendor=patterns.get("vendor", ""),
                        detection_patterns=[pattern],
                        evidence_sources=[f"Source usage: {match.group(0)}"]
                    )
                    
                    self.detected_libraries.append(library_info)
    
    def _analyze_manifest_libraries(self) -> None:
        """Analyze AndroidManifest.xml for library references."""
        logger.debug("Analyzing manifest libraries")
        
        try:
            manifest_content = self._extract_manifest()
            if manifest_content:
                self._parse_manifest_content(manifest_content)
                
        except Exception as e:
            logger.error(f"Manifest analysis failed: {e}")
    
    def _extract_manifest(self) -> Optional[str]:
        """Extract AndroidManifest.xml from APK."""
        try:
            with zipfile.ZipFile(self.apk_path, 'r') as apk_zip:
                manifest_content = apk_zip.read('AndroidManifest.xml')
                return manifest_content.decode('utf-8', errors='ignore')
        except Exception as e:
            logger.error(f"Failed to extract manifest: {e}")
            return None
    
    def _parse_manifest_content(self, content: str) -> None:
        """Parse manifest content for library references."""
        for library_name, patterns in self.library_patterns.items():
            manifest_patterns = patterns.get("manifest_patterns", [])
            
            for pattern in manifest_patterns:
                matches = re.finditer(pattern, content, re.MULTILINE | re.IGNORECASE)
                
                for match in matches:
                    version = self._extract_version_from_match(match)
                    
                    library_info = LibraryInfo(
                        name=library_name,
                        version=version,
                        location="AndroidManifest.xml",
                        detection_method=DetectionMethod.MANIFEST_ANALYSIS,
                        confidence=0.6,  # Lower confidence for manifest analysis
                        file_path="AndroidManifest.xml",
                        library_type=patterns.get("library_type", LibraryType.UTILITY),
                        vendor=patterns.get("vendor", ""),
                        detection_patterns=[pattern],
                        evidence_sources=[f"Manifest reference: {match.group(0)}"]
                    )
                    
                    self.detected_libraries.append(library_info)
    
    def _extract_version_from_match(self, match) -> str:
        """Extract version from regex match."""
        if match.groups():
            return match.group(1)
        else:
            # Try to extract version from the full match
            version_match = re.search(r'([0-9]+\.[0-9]+(?:\.[0-9]+)?(?:[a-z]+)?)', match.group(0))
            return version_match.group(1) if version_match else "unknown"
    
    def _deduplicate_detections(self) -> None:
        """Remove duplicate detections and merge information using unified deduplication framework."""
        if not self.detected_libraries:
            return
        
        try:
            # Import unified deduplication framework
            from core.unified_deduplication_framework import (
                deduplicate_findings,
                DeduplicationStrategy
            )
            
            # Convert library detections to dictionaries for unified deduplication
            dict_findings = []
            for lib in self.detected_libraries:
                dict_finding = {
                    'title': f"Library Detected: {lib.name}",
                    'file_path': lib.file_path,
                    'severity': 'INFO',  # Library detection is informational
                    'category': 'library_detection',
                    'description': f"Library {lib.name} version {lib.version} detected using {lib.detection_method}",
                    'library_name': lib.name,
                    'version': lib.version,
                    'confidence': lib.confidence,
                    'finding_id': id(lib)
                }
                dict_findings.append(dict_finding)
            
            # Use unified deduplication framework with INTELLIGENT strategy for library detection
            result = deduplicate_findings(dict_findings, DeduplicationStrategy.INTELLIGENT)
            
            # Map deduplicated results back to original library detections
            unique_lib_ids = {f['finding_id'] for f in result.unique_findings}
            deduplicated_libraries = [lib for lib in self.detected_libraries if id(lib) in unique_lib_ids]
            
            # Apply domain-specific library merging to the deduplicated set
            merged_libraries = self._apply_library_specific_merging(deduplicated_libraries)
            
            # Log deduplication results for transparency
            original_count = len(self.detected_libraries)
            final_count = len(merged_libraries)
            if original_count != final_count:
                removed_count = original_count - final_count
                logging.getLogger(__name__).info(f"Library deduplication: {original_count} -> {final_count} "
                                                f"({removed_count} duplicates removed)")
            
            self.detected_libraries = merged_libraries
            
        except Exception as e:
            # Fallback to original custom deduplication
            logging.getLogger(__name__).warning(f"Unified deduplication failed, using fallback: {e}")
            self._deduplicate_detections_fallback()
    
    def _deduplicate_detections_fallback(self) -> None:
        """Fallback deduplication method (original logic)."""
        # Group detections by library name
        library_groups = {}
        for lib in self.detected_libraries:
            key = lib.name
            if key not in library_groups:
                library_groups[key] = []
            library_groups[key].append(lib)
        
        # Merge detections for each library
        merged_libraries = []
        for library_name, detections in library_groups.items():
            merged_lib = self._merge_library_detections(detections)
            merged_libraries.append(merged_lib)
        
        self.detected_libraries = merged_libraries
    
    def _apply_library_specific_merging(self, libraries: List) -> List:
        """Apply library-specific merging logic after unified deduplication."""
        # Group remaining detections by library name for merging
        library_groups = {}
        for lib in libraries:
            key = lib.name
            if key not in library_groups:
                library_groups[key] = []
            library_groups[key].append(lib)
        
        # Merge detections for each library
        merged_libraries = []
        for library_name, detections in library_groups.items():
            merged_lib = self._merge_library_detections(detections)
            merged_libraries.append(merged_lib)
        
        return merged_libraries
    
    def _merge_library_detections(self, detections: List[LibraryInfo]) -> LibraryInfo:
        """Merge multiple detections of the same library."""
        if len(detections) == 1:
            return detections[0]
        
        # Use the detection with highest confidence as base
        base_detection = max(detections, key=lambda x: x.confidence)
        
        # Merge information from all detections
        all_patterns = []
        all_evidence = []
        all_locations = set()
        
        for detection in detections:
            all_patterns.extend(detection.detection_patterns)
            all_evidence.extend(detection.evidence_sources)
            all_locations.add(detection.location)
        
        # Create merged detection
        merged = LibraryInfo(
            name=base_detection.name,
            version=self._get_best_version(detections),
            location="; ".join(all_locations),
            detection_method=base_detection.detection_method,
            confidence=min(1.0, base_detection.confidence * 1.1),  # Boost confidence for multiple detections
            file_path=base_detection.file_path,
            checksum=base_detection.checksum,
            library_type=base_detection.library_type,
            vendor=base_detection.vendor,
            detection_patterns=list(set(all_patterns)),
            evidence_sources=list(set(all_evidence))
        )
        
        return merged
    
    def _get_best_version(self, detections: List[LibraryInfo]) -> str:
        """Get the best version from multiple detections."""
        # Prefer versions that are not "unknown" or "detected"
        versions = [d.version for d in detections if d.version not in ["unknown", "detected"]]
        
        if versions:
            # Return the most common version
            from collections import Counter
            return Counter(versions).most_common(1)[0][0]
        else:
            return "detected" 