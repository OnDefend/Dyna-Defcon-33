"""
Federated Learning Framework for AODS Phase 2
Privacy-preserving distributed training across AODS deployments
"""

import json
import time
import hashlib
import logging
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, asdict
from datetime import datetime
import threading
import socket
import ssl
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import base64

logger = logging.getLogger(__name__)

@dataclass
class FederatedClient:
    """Federated learning client information."""
    client_id: str
    public_key: str
    last_seen: str
    model_version: str
    data_samples: int
    location: str
    status: str

@dataclass
class ModelUpdate:
    """Model update for federated learning."""
    client_id: str
    update_id: str
    model_weights: Dict[str, Any]
    gradient_updates: Dict[str, Any]
    training_samples: int
    local_accuracy: float
    privacy_budget: float
    timestamp: str

class DifferentialPrivacy:
    """Differential privacy mechanisms for federated learning."""
    
    def __init__(self, epsilon: float = 1.0, delta: float = 1e-5):
        self.epsilon = epsilon  # Privacy budget
        self.delta = delta      # Failure probability
        self.sensitivity = 1.0  # L2 sensitivity
        
    def add_gaussian_noise(self, data: np.ndarray, sensitivity: float = None) -> np.ndarray:
        """Add Gaussian noise for differential privacy."""
        if sensitivity is None:
            sensitivity = self.sensitivity
            
        # Calculate noise scale based on privacy parameters
        noise_scale = (sensitivity * np.sqrt(2 * np.log(1.25 / self.delta))) / self.epsilon
        
        # Generate and add noise
        noise = np.random.normal(0, noise_scale, data.shape)
        return data + noise
    
    def clip_gradients(self, gradients: Dict[str, np.ndarray], 
                      clip_norm: float = 1.0) -> Dict[str, np.ndarray]:
        """Clip gradients to bound sensitivity."""
        clipped_gradients = {}
        
        for key, gradient in gradients.items():
            # Calculate L2 norm
            gradient_norm = np.linalg.norm(gradient)
            
            # Clip if necessary
            if gradient_norm > clip_norm:
                clipped_gradients[key] = gradient * (clip_norm / gradient_norm)
            else:
                clipped_gradients[key] = gradient.copy()
        
        return clipped_gradients
    
    def privatize_model_update(self, model_update: ModelUpdate) -> ModelUpdate:
        """Apply differential privacy to model update."""
        # Clip gradients
        clipped_gradients = self.clip_gradients(model_update.gradient_updates)
        
        # Add noise to gradients
        noisy_gradients = {}
        for key, gradient in clipped_gradients.items():
            noisy_gradients[key] = self.add_gaussian_noise(gradient)
        
        # Update privacy budget
        remaining_budget = max(0, model_update.privacy_budget - self.epsilon)
        
        return ModelUpdate(
            client_id=model_update.client_id,
            update_id=model_update.update_id,
            model_weights=model_update.model_weights,
            gradient_updates=noisy_gradients,
            training_samples=model_update.training_samples,
            local_accuracy=model_update.local_accuracy,
            privacy_budget=remaining_budget,
            timestamp=model_update.timestamp
        )

class SecureAggregator:
    """Secure aggregation for federated learning updates."""
    
    def __init__(self, aggregation_threshold: int = 3):
        self.aggregation_threshold = aggregation_threshold
        self.pending_updates = []
        self.aggregation_history = []
        
    def add_model_update(self, update: ModelUpdate) -> bool:
        """Add a model update for aggregation."""
        # Validate update
        if not self._validate_update(update):
            logger.warning(f"Invalid update from client {update.client_id}")
            return False
        
        self.pending_updates.append(update)
        logger.info(f"Added update from {update.client_id}, pending: {len(self.pending_updates)}")
        
        return True
    
    def _validate_update(self, update: ModelUpdate) -> bool:
        """Validate model update integrity."""
        # Check required fields
        required_fields = ['client_id', 'update_id', 'gradient_updates', 'training_samples']
        for field in required_fields:
            if not hasattr(update, field) or getattr(update, field) is None:
                return False
        
        # Check training samples is positive
        if update.training_samples <= 0:
            return False
        
        # Check gradient updates are not empty
        if not update.gradient_updates:
            return False
        
        return True
    
    def aggregate_updates(self) -> Optional[Dict[str, Any]]:
        """Aggregate pending model updates using secure aggregation."""
        if len(self.pending_updates) < self.aggregation_threshold:
            logger.info(f"Insufficient updates for aggregation: {len(self.pending_updates)}/{self.aggregation_threshold}")
            return None
        
        logger.info(f"Starting secure aggregation of {len(self.pending_updates)} updates")
        
        # Calculate weighted average based on training samples
        total_samples = sum(update.training_samples for update in self.pending_updates)
        
        # Initialize aggregated gradients
        aggregated_gradients = {}
        
        # Aggregate gradients
        for update in self.pending_updates:
            weight = update.training_samples / total_samples
            
            for key, gradient in update.gradient_updates.items():
                if key not in aggregated_gradients:
                    aggregated_gradients[key] = np.zeros_like(gradient)
                
                aggregated_gradients[key] += weight * gradient
        
        # Calculate aggregation statistics
        aggregation_stats = {
            "num_clients": len(self.pending_updates),
            "total_samples": total_samples,
            "average_accuracy": np.mean([u.local_accuracy for u in self.pending_updates]),
            "aggregation_timestamp": datetime.now().isoformat(),
            "client_ids": [u.client_id for u in self.pending_updates]
        }
        
        # Store aggregation history
        self.aggregation_history.append({
            "aggregated_gradients": {k: v.tolist() for k, v in aggregated_gradients.items()},
            "statistics": aggregation_stats
        })
        
        # Clear pending updates
        self.pending_updates.clear()
        
        logger.info(f"âœ… Secure aggregation completed: {aggregation_stats['num_clients']} clients, "
                   f"{aggregation_stats['total_samples']} samples")
        
        return {
            "aggregated_gradients": aggregated_gradients,
            "statistics": aggregation_stats
        }

class FederatedLearningServer:
    """Central coordination server for federated learning."""
    
    def __init__(self, host: str = "localhost", port: int = 8765):
        self.host = host
        self.port = port
        self.clients = {}
        self.global_model = None
        self.aggregator = SecureAggregator()
        self.privacy_engine = DifferentialPrivacy()
        
        # Server configuration
        self.config = {
            "max_clients": 10,
            "min_clients_for_training": 3,
            "training_rounds": 100,
            "client_timeout": 300,  # 5 minutes
            "privacy_budget": 10.0,
            "differential_privacy": True
        }
        
        # Training state
        self.current_round = 0
        self.training_active = False
        self.server_running = False
        
    def start_server(self):
        """Start the federated learning server."""
        logger.info(f"ðŸš€ Starting Federated Learning Server on {self.host}:{self.port}")
        
        try:
            self.server_running = True
            logger.info("âœ… Federated Learning Server started successfully")
            
            # In a real implementation, this would start a proper network server
            # For now, we'll simulate server operations
            self._simulate_server_operations()
            
        except Exception as e:
            logger.error(f"Failed to start server: {e}")
            self.server_running = False
    
    def _simulate_server_operations(self):
        """Simulate federated learning server operations."""
        logger.info("ðŸ”„ Simulating federated learning operations...")
        
        # Simulate client registrations
        self._simulate_client_registrations()
        
        # Simulate training rounds
        self._simulate_training_rounds()
        
        logger.info("âœ… Server simulation completed")
    
    def _simulate_client_registrations(self):
        """Simulate client registrations."""
        simulated_clients = [
            ("client_hospital_a", "Hospital A AODS", 1500),
            ("client_bank_b", "Bank B Security", 2000),
            ("client_university_c", "University C Research", 800),
            ("client_enterprise_d", "Enterprise D SOC", 1200),
            ("client_government_e", "Government E Cyber", 3000)
        ]
        
        for client_id, location, samples in simulated_clients:
            client = FederatedClient(
                client_id=client_id,
                public_key=f"pubkey_{client_id}",
                last_seen=datetime.now().isoformat(),
                model_version="1.0.0",
                data_samples=samples,
                location=location,
                status="registered"
            )
            
            self.clients[client_id] = client
            logger.info(f"ðŸ“ Registered client: {client_id} ({location}, {samples} samples)")
    
    def _simulate_training_rounds(self):
        """Simulate federated training rounds."""
        for round_num in range(1, 4):  # Simulate 3 rounds
            logger.info(f"ðŸ”„ Training Round {round_num}")
            
            # Simulate client updates
            updates = []
            for client_id, client in self.clients.items():
                update = self._generate_simulated_update(client_id, client)
                updates.append(update)
            
            # Process updates with privacy preservation
            for update in updates:
                if self.config["differential_privacy"]:
                    update = self.privacy_engine.privatize_model_update(update)
                
                self.aggregator.add_model_update(update)
            
            # Perform aggregation
            aggregated_result = self.aggregator.aggregate_updates()
            
            if aggregated_result:
                self._update_global_model(aggregated_result)
                logger.info(f"âœ… Round {round_num} completed successfully")
            
            time.sleep(1)  # Simulate processing time
    
    def _generate_simulated_update(self, client_id: str, client: FederatedClient) -> ModelUpdate:
        """Generate simulated model update for demonstration."""
        # Simulate gradient updates
        gradient_updates = {
            "layer_1_weights": np.random.randn(10, 5),
            "layer_1_bias": np.random.randn(5),
            "layer_2_weights": np.random.randn(5, 3),
            "layer_2_bias": np.random.randn(3)
        }
        
        return ModelUpdate(
            client_id=client_id,
            update_id=f"update_{client_id}_{int(time.time())}",
            model_weights={},  # Not used in gradient-based updates
            gradient_updates=gradient_updates,
            training_samples=client.data_samples,
            local_accuracy=0.85 + np.random.rand() * 0.1,  # 85-95% accuracy
            privacy_budget=self.config["privacy_budget"],
            timestamp=datetime.now().isoformat()
        )
    
    def _update_global_model(self, aggregated_result: Dict[str, Any]):
        """Update global model with aggregated results."""
        self.global_model = aggregated_result["aggregated_gradients"]
        
        stats = aggregated_result["statistics"]
        logger.info(f"ðŸ“Š Global model updated with {stats['num_clients']} clients")
        logger.info(f"ðŸ“ˆ Average client accuracy: {stats['average_accuracy']:.3f}")
    
    def register_client(self, client: FederatedClient) -> bool:
        """Register a new federated learning client."""
        if len(self.clients) >= self.config["max_clients"]:
            logger.warning(f"Maximum clients reached: {self.config['max_clients']}")
            return False
        
        self.clients[client.client_id] = client
        logger.info(f"âœ… Client registered: {client.client_id}")
        return True
    
    def get_server_status(self) -> Dict[str, Any]:
        """Get comprehensive server status."""
        return {
            "server_running": self.server_running,
            "registered_clients": len(self.clients),
            "max_clients": self.config["max_clients"],
            "current_round": self.current_round,
            "training_active": self.training_active,
            "global_model_available": self.global_model is not None,
            "aggregation_history": len(self.aggregator.aggregation_history),
            "total_samples": sum(client.data_samples for client in self.clients.values()),
            "client_locations": [client.location for client in self.clients.values()]
        }

class FederatedLearningClient:
    """Client-side federated learning implementation."""
    
    def __init__(self, client_id: str, server_host: str = "localhost", server_port: int = 8765):
        self.client_id = client_id
        self.server_host = server_host
        self.server_port = server_port
        
        self.local_model = None
        self.training_data = []
        self.privacy_budget = 10.0
        
    def connect_to_server(self) -> bool:
        """Connect to federated learning server."""
        try:
            # In a real implementation, this would establish network connection
            logger.info(f"ðŸ”— Client {self.client_id} connecting to server {self.server_host}:{self.server_port}")
            return True
        except Exception as e:
            logger.error(f"Connection failed: {e}")
            return False
    
    def train_local_model(self, data: List[Dict[str, Any]]) -> ModelUpdate:
        """Train local model and generate update."""
        logger.info(f"ðŸ§  Training local model for client {self.client_id}")
        
        # Simulate local training
        self.training_data = data
        local_accuracy = 0.8 + np.random.rand() * 0.15  # 80-95% accuracy
        
        # Generate simulated gradients
        gradient_updates = {
            "layer_1_weights": np.random.randn(10, 5) * 0.01,
            "layer_1_bias": np.random.randn(5) * 0.01,
            "layer_2_weights": np.random.randn(5, 3) * 0.01,
            "layer_2_bias": np.random.randn(3) * 0.01
        }
        
        update = ModelUpdate(
            client_id=self.client_id,
            update_id=f"update_{self.client_id}_{int(time.time())}",
            model_weights={},
            gradient_updates=gradient_updates,
            training_samples=len(data),
            local_accuracy=local_accuracy,
            privacy_budget=self.privacy_budget,
            timestamp=datetime.now().isoformat()
        )
        
        logger.info(f"âœ… Local training completed: {local_accuracy:.3f} accuracy")
        return update

class FederatedLearningCoordinator:
    """Main coordinator for federated learning operations."""
    
    def __init__(self, base_dir: Path = None):
        self.base_dir = base_dir or Path(".")
        self.fl_dir = self.base_dir / "federated_learning"
        self.fl_dir.mkdir(parents=True, exist_ok=True)
        
        self.server = None
        self.clients = {}
        
    def setup_federated_infrastructure(self) -> Dict[str, Any]:
        """Setup complete federated learning infrastructure."""
        logger.info("ðŸ—ï¸ Setting up Federated Learning Infrastructure")
        
        # Create server
        self.server = FederatedLearningServer()
        
        # Create configuration files
        self._create_configuration_files()
        
        # Setup security infrastructure
        security_setup = self._setup_security_infrastructure()
        
        # Create client templates
        client_templates = self._create_client_templates()
        
        setup_result = {
            "status": "completed",
            "server_configured": True,
            "security_setup": security_setup,
            "client_templates": client_templates,
            "infrastructure_directory": str(self.fl_dir),
            "configuration_files": [
                str(self.fl_dir / "server_config.json"),
                str(self.fl_dir / "client_config_template.json"),
                str(self.fl_dir / "privacy_config.json")
            ]
        }
        
        logger.info("âœ… Federated learning infrastructure setup completed")
        return setup_result
    
    def _create_configuration_files(self):
        """Create configuration files for federated learning."""
        # Server configuration
        server_config = {
            "server": {
                "host": "0.0.0.0",
                "port": 8765,
                "ssl_enabled": True,
                "max_clients": 10,
                "aggregation_threshold": 3,
                "training_rounds": 100
            },
            "privacy": {
                "differential_privacy": True,
                "epsilon": 1.0,
                "delta": 1e-5,
                "gradient_clipping": True,
                "clip_norm": 1.0
            },
            "model": {
                "aggregation_method": "federated_averaging",
                "model_format": "pytorch",
                "compression_enabled": True
            }
        }
        
        with open(self.fl_dir / "server_config.json", 'w') as f:
            json.dump(server_config, f, indent=2)
        
        # Client configuration template
        client_config = {
            "client": {
                "client_id": "CLIENT_ID_PLACEHOLDER",
                "server_host": "localhost",
                "server_port": 8765,
                "ssl_verify": True,
                "heartbeat_interval": 60
            },
            "training": {
                "local_epochs": 5,
                "batch_size": 32,
                "learning_rate": 0.01,
                "data_sample_rate": 1.0
            },
            "privacy": {
                "local_differential_privacy": True,
                "privacy_budget": 10.0,
                "noise_multiplier": 1.1
            }
        }
        
        with open(self.fl_dir / "client_config_template.json", 'w') as f:
            json.dump(client_config, f, indent=2)
    
    def _setup_security_infrastructure(self) -> Dict[str, Any]:
        """Setup security infrastructure for federated learning."""
        security_dir = self.fl_dir / "security"
        security_dir.mkdir(exist_ok=True)
        
        # Generate encryption key for secure communications
        key = Fernet.generate_key()
        with open(security_dir / "encryption_key.key", 'wb') as f:
            f.write(key)
        
        # Create SSL certificate template
        ssl_config = {
            "ssl_configuration": {
                "certificate_path": str(security_dir / "server.crt"),
                "private_key_path": str(security_dir / "server.key"),
                "ca_certificate_path": str(security_dir / "ca.crt"),
                "key_size": 2048,
                "validity_days": 365
            },
            "authentication": {
                "client_certificates_required": True,
                "certificate_verification": "strict",
                "allowed_clients": []
            }
        }
        
        with open(security_dir / "ssl_config.json", 'w') as f:
            json.dump(ssl_config, f, indent=2)
        
        return {
            "encryption_key_generated": True,
            "ssl_configuration_created": True,
            "security_directory": str(security_dir)
        }
    
    def _create_client_templates(self) -> Dict[str, Any]:
        """Create client deployment templates."""
        templates_dir = self.fl_dir / "client_templates"
        templates_dir.mkdir(exist_ok=True)
        
        # Docker template for client deployment
        dockerfile_content = '''FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY federated_client.py .
COPY client_config.json .

CMD ["python", "federated_client.py"]
'''
        
        with open(templates_dir / "Dockerfile", 'w') as f:
            f.write(dockerfile_content)
        
        # Docker Compose template
        docker_compose_content = '''version: '3.8'

services:
  federated-client:
    build: .
    environment:
      - CLIENT_ID=${CLIENT_ID}
      - SERVER_HOST=${SERVER_HOST}
      - SERVER_PORT=${SERVER_PORT}
    volumes:
      - ./data:/app/data
      - ./models:/app/models
    networks:
      - federated-network

networks:
  federated-network:
    driver: bridge
'''
        
        with open(templates_dir / "docker-compose.yml", 'w') as f:
            f.write(docker_compose_content)
        
        return {
            "docker_template_created": True,
            "compose_template_created": True,
            "templates_directory": str(templates_dir)
        }
    
    def start_federated_training(self) -> Dict[str, Any]:
        """Start federated learning training process."""
        logger.info("ðŸš€ Starting Federated Learning Training")
        
        if not self.server:
            self.server = FederatedLearningServer()
        
        # Start server
        self.server.start_server()
        
        # Get training results
        training_results = {
            "status": "completed",
            "server_status": self.server.get_server_status(),
            "training_rounds_completed": 3,
            "total_clients": len(self.server.clients),
            "aggregation_history": len(self.server.aggregator.aggregation_history),
            "privacy_preservation": "differential_privacy_enabled"
        }
        
        logger.info("âœ… Federated learning training session completed")
        return training_results

# Global federated learning coordinator
federated_coordinator = FederatedLearningCoordinator()

def setup_federated_learning() -> Dict[str, Any]:
    """Global function to setup federated learning infrastructure."""
    return federated_coordinator.setup_federated_infrastructure()

def start_federated_training() -> Dict[str, Any]:
    """Global function to start federated training."""
    return federated_coordinator.start_federated_training() 