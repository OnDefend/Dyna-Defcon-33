"""
Vulnerability Trend Analyzer for AODS Advanced Analytics
Track vulnerability patterns, trends, and provide predictive insights
"""

import json
import time
import sqlite3
import logging
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import statistics

logger = logging.getLogger(__name__)

@dataclass
class VulnerabilityTrend:
    """Vulnerability trend data structure."""
    vulnerability_type: str
    trend_direction: str  # increasing, decreasing, stable
    change_rate: float
    severity_distribution: Dict[str, int]
    confidence_trend: float
    first_seen: str
    last_seen: str
    total_occurrences: int
    trend_strength: float

@dataclass
class TrendAnalysis:
    """Complete trend analysis result."""
    analysis_date: str
    time_period: str
    total_vulnerabilities: int
    trending_up: List[VulnerabilityTrend]
    trending_down: List[VulnerabilityTrend]
    stable_trends: List[VulnerabilityTrend]
    emerging_threats: List[str]
    declining_threats: List[str]
    severity_trends: Dict[str, float]
    confidence_trends: Dict[str, float]

class VulnerabilityDatabase:
    """Database manager for vulnerability tracking and analysis."""
    
    def __init__(self, db_path: Path):
        self.db_path = db_path
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._init_database()
    
    def _init_database(self):
        """Initialize vulnerability tracking database."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Main vulnerabilities table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS vulnerabilities (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                apk_name TEXT NOT NULL,
                apk_hash TEXT,
                vulnerability_type TEXT NOT NULL,
                severity TEXT NOT NULL,
                confidence_score REAL,
                description TEXT,
                file_path TEXT,
                line_number INTEGER,
                plugin_name TEXT,
                detected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                metadata TEXT
            )
        ''')
        
        # Trend snapshots table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS trend_snapshots (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                snapshot_date TEXT NOT NULL,
                vulnerability_type TEXT NOT NULL,
                count INTEGER NOT NULL,
                avg_confidence REAL,
                severity_distribution TEXT,
                trend_metadata TEXT
            )
        ''')
        
        # APK analysis sessions
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS analysis_sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT UNIQUE NOT NULL,
                apk_name TEXT NOT NULL,
                apk_size INTEGER,
                analysis_start TIMESTAMP,
                analysis_end TIMESTAMP,
                total_vulnerabilities INTEGER,
                session_metadata TEXT
            )
        ''')
        
        # Create indexes for efficient querying
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_vuln_type ON vulnerabilities(vulnerability_type)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_detected_at ON vulnerabilities(detected_at)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_severity ON vulnerabilities(severity)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_apk_name ON vulnerabilities(apk_name)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_snapshot_date ON trend_snapshots(snapshot_date)')
        
        conn.commit()
        conn.close()
        
        logger.info(f"Vulnerability database initialized: {self.db_path}")
    
    def store_vulnerability(self, apk_name: str, vulnerability_data: Dict[str, Any]) -> bool:
        """Store vulnerability finding in database."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO vulnerabilities 
                (apk_name, apk_hash, vulnerability_type, severity, confidence_score,
                 description, file_path, line_number, plugin_name, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                apk_name,
                vulnerability_data.get('apk_hash', ''),
                vulnerability_data.get('vulnerability_type', 'unknown'),
                vulnerability_data.get('severity', 'medium'),
                vulnerability_data.get('confidence_score', 0.5),
                vulnerability_data.get('description', ''),
                vulnerability_data.get('file_path', ''),
                vulnerability_data.get('line_number'),
                vulnerability_data.get('plugin_name', ''),
                json.dumps(vulnerability_data.get('metadata', {}))
            ))
            
            conn.commit()
            conn.close()
            return True
            
        except Exception as e:
            logger.error(f"Failed to store vulnerability: {e}")
            return False
    
    def get_vulnerabilities_by_timeframe(self, days: int = 30) -> List[Dict[str, Any]]:
        """Get vulnerabilities from the last N days."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cutoff_date = datetime.now() - timedelta(days=days)
            
            cursor.execute('''
                SELECT * FROM vulnerabilities 
                WHERE detected_at >= ? 
                ORDER BY detected_at DESC
            ''', (cutoff_date.isoformat(),))
            
            columns = [desc[0] for desc in cursor.description]
            vulnerabilities = []
            
            for row in cursor.fetchall():
                vuln_dict = dict(zip(columns, row))
                if vuln_dict['metadata']:
                    vuln_dict['metadata'] = json.loads(vuln_dict['metadata'])
                vulnerabilities.append(vuln_dict)
            
            conn.close()
            return vulnerabilities
            
        except Exception as e:
            logger.error(f"Failed to get vulnerabilities by timeframe: {e}")
            return []
    
    def store_trend_snapshot(self, vulnerability_type: str, count: int, 
                           avg_confidence: float, severity_dist: Dict[str, int]) -> bool:
        """Store trend snapshot for analysis."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO trend_snapshots 
                (snapshot_date, vulnerability_type, count, avg_confidence, severity_distribution)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                datetime.now().isoformat(),
                vulnerability_type,
                count,
                avg_confidence,
                json.dumps(severity_dist)
            ))
            
            conn.commit()
            conn.close()
            return True
            
        except Exception as e:
            logger.error(f"Failed to store trend snapshot: {e}")
            return False

class VulnerabilityTrendAnalyzer:
    """Main vulnerability trend analyzer."""
    
    def __init__(self, base_dir: Path = None):
        self.base_dir = base_dir or Path(".")
        self.analytics_dir = self.base_dir / "analytics" / "trends"
        self.analytics_dir.mkdir(parents=True, exist_ok=True)
        
        # Initialize database
        self.db = VulnerabilityDatabase(self.analytics_dir / "vulnerability_trends.db")
        
        # Analysis configuration
        self.config = {
            "trend_analysis_days": 30,
            "minimum_occurrences": 5,
            "trend_threshold": 0.1,  # 10% change to be considered trending
            "emerging_threat_threshold": 3,  # 3+ new occurrences in recent period
            "confidence_trends": True,
            "severity_analysis": True
        }
        
        # Vulnerability categories for analysis
        self.vulnerability_categories = {
            "injection": ["sql_injection", "command_injection", "ldap_injection", "xpath_injection"],
            "xss": ["reflected_xss", "stored_xss", "dom_xss"],
            "crypto": ["weak_encryption", "hardcoded_key", "insecure_random", "weak_hash"],
            "access_control": ["path_traversal", "privilege_escalation", "authentication_bypass"],
            "data_exposure": ["sensitive_data_exposure", "information_disclosure", "data_leak"],
            "mobile_specific": ["exported_component", "debug_enabled", "backup_enabled", "intent_hijacking"]
        }
    
    def analyze_vulnerability_trends(self, time_period_days: int = 30) -> TrendAnalysis:
        """Perform comprehensive vulnerability trend analysis."""
        logger.info(f"🔍 Analyzing vulnerability trends for {time_period_days} days")
        
        # Get vulnerability data
        vulnerabilities = self.db.get_vulnerabilities_by_timeframe(time_period_days)
        
        if not vulnerabilities:
            logger.warning("No vulnerability data available for trend analysis")
            return self._create_empty_analysis(time_period_days)
        
        # Analyze trends by vulnerability type
        vulnerability_trends = self._analyze_by_type(vulnerabilities, time_period_days)
        
        # Categorize trends
        trending_up = [t for t in vulnerability_trends if t.trend_direction == "increasing"]
        trending_down = [t for t in vulnerability_trends if t.trend_direction == "decreasing"]
        stable_trends = [t for t in vulnerability_trends if t.trend_direction == "stable"]
        
        # Identify emerging and declining threats
        emerging_threats = self._identify_emerging_threats(vulnerabilities, time_period_days)
        declining_threats = self._identify_declining_threats(vulnerabilities, time_period_days)
        
        # Analyze severity trends
        severity_trends = self._analyze_severity_trends(vulnerabilities, time_period_days)
        
        # Analyze confidence trends
        confidence_trends = self._analyze_confidence_trends(vulnerabilities, time_period_days)
        
        # Create comprehensive analysis
        analysis = TrendAnalysis(
            analysis_date=datetime.now().isoformat(),
            time_period=f"{time_period_days} days",
            total_vulnerabilities=len(vulnerabilities),
            trending_up=sorted(trending_up, key=lambda x: x.trend_strength, reverse=True),
            trending_down=sorted(trending_down, key=lambda x: x.trend_strength, reverse=True),
            stable_trends=stable_trends,
            emerging_threats=emerging_threats,
            declining_threats=declining_threats,
            severity_trends=severity_trends,
            confidence_trends=confidence_trends
        )
        
        # Store trend snapshots
        self._store_trend_snapshots(vulnerability_trends)
        
        logger.info(f"✅ Trend analysis completed: {len(vulnerability_trends)} types analyzed")
        
        return analysis
    
    def _analyze_by_type(self, vulnerabilities: List[Dict[str, Any]], 
                        time_period_days: int) -> List[VulnerabilityTrend]:
        """Analyze trends by vulnerability type."""
        
        # Group vulnerabilities by type and time
        type_timeline = defaultdict(list)
        type_severity = defaultdict(Counter)
        type_confidence = defaultdict(list)
        
        for vuln in vulnerabilities:
            vuln_type = vuln['vulnerability_type']
            detected_at = datetime.fromisoformat(vuln['detected_at'])
            
            type_timeline[vuln_type].append(detected_at)
            type_severity[vuln_type][vuln['severity']] += 1
            type_confidence[vuln_type].append(vuln['confidence_score'])
        
        trends = []
        
        for vuln_type in type_timeline:
            timestamps = type_timeline[vuln_type]
            
            if len(timestamps) < self.config["minimum_occurrences"]:
                continue
            
            # Calculate trend
            trend_direction, change_rate, trend_strength = self._calculate_trend(
                timestamps, time_period_days
            )
            
            # Get severity distribution
            severity_dist = dict(type_severity[vuln_type])
            
            # Calculate average confidence
            avg_confidence = statistics.mean(type_confidence[vuln_type])
            
            trend = VulnerabilityTrend(
                vulnerability_type=vuln_type,
                trend_direction=trend_direction,
                change_rate=change_rate,
                severity_distribution=severity_dist,
                confidence_trend=avg_confidence,
                first_seen=min(timestamps).isoformat(),
                last_seen=max(timestamps).isoformat(),
                total_occurrences=len(timestamps),
                trend_strength=trend_strength
            )
            
            trends.append(trend)
        
        return trends
    
    def _calculate_trend(self, timestamps: List[datetime], 
                        time_period_days: int) -> Tuple[str, float, float]:
        """Calculate trend direction and strength."""
        
        # Divide time period into buckets
        num_buckets = min(7, time_period_days)  # Weekly buckets or daily if short period
        bucket_size = time_period_days / num_buckets
        
        now = datetime.now()
        buckets = [0] * num_buckets
        
        for timestamp in timestamps:
            days_ago = (now - timestamp).days
            bucket_index = min(int(days_ago / bucket_size), num_buckets - 1)
            # Reverse index so recent is at the end
            buckets[num_buckets - 1 - bucket_index] += 1
        
        if len(buckets) < 2:
            return "stable", 0.0, 0.0
        
        # Calculate trend using linear regression
        x = np.arange(len(buckets))
        y = np.array(buckets)
        
        if np.sum(y) == 0:
            return "stable", 0.0, 0.0
        
        # Simple linear trend calculation
        if len(x) > 1:
            slope = np.polyfit(x, y, 1)[0]
            
            # Normalize slope by average occurrences
            avg_occurrences = np.mean(y)
            if avg_occurrences > 0:
                normalized_slope = slope / avg_occurrences
            else:
                normalized_slope = 0
            
            # Determine trend direction
            if abs(normalized_slope) < self.config["trend_threshold"]:
                direction = "stable"
            elif normalized_slope > 0:
                direction = "increasing"
            else:
                direction = "decreasing"
            
            trend_strength = abs(normalized_slope)
            
            return direction, normalized_slope, trend_strength
        
        return "stable", 0.0, 0.0
    
    def _identify_emerging_threats(self, vulnerabilities: List[Dict[str, Any]], 
                                  time_period_days: int) -> List[str]:
        """Identify emerging threat patterns."""
        
        # Look at recent period (last 25% of time period)
        recent_days = max(1, time_period_days // 4)
        cutoff_date = datetime.now() - timedelta(days=recent_days)
        
        recent_vulns = [v for v in vulnerabilities 
                       if datetime.fromisoformat(v['detected_at']) >= cutoff_date]
        
        # Count recent occurrences by type
        recent_counts = Counter(v['vulnerability_type'] for v in recent_vulns)
        
        # Get historical baseline
        historical_vulns = [v for v in vulnerabilities 
                           if datetime.fromisoformat(v['detected_at']) < cutoff_date]
        historical_counts = Counter(v['vulnerability_type'] for v in historical_vulns)
        
        emerging = []
        
        for vuln_type, recent_count in recent_counts.items():
            historical_count = historical_counts.get(vuln_type, 0)
            
            # Consider emerging if:
            # 1. Recent occurrences exceed threshold
            # 2. Significant increase from historical baseline
            if (recent_count >= self.config["emerging_threat_threshold"] and
                recent_count > historical_count * 1.5):
                emerging.append(vuln_type)
        
        return sorted(emerging, key=lambda x: recent_counts[x], reverse=True)
    
    def _identify_declining_threats(self, vulnerabilities: List[Dict[str, Any]], 
                                   time_period_days: int) -> List[str]:
        """Identify declining threat patterns."""
        
        # Look at recent vs historical periods
        recent_days = max(1, time_period_days // 4)
        cutoff_date = datetime.now() - timedelta(days=recent_days)
        
        recent_vulns = [v for v in vulnerabilities 
                       if datetime.fromisoformat(v['detected_at']) >= cutoff_date]
        historical_vulns = [v for v in vulnerabilities 
                           if datetime.fromisoformat(v['detected_at']) < cutoff_date]
        
        recent_counts = Counter(v['vulnerability_type'] for v in recent_vulns)
        historical_counts = Counter(v['vulnerability_type'] for v in historical_vulns)
        
        declining = []
        
        for vuln_type, historical_count in historical_counts.items():
            recent_count = recent_counts.get(vuln_type, 0)
            
            # Consider declining if significant reduction
            if (historical_count >= self.config["emerging_threat_threshold"] and
                recent_count < historical_count * 0.5):
                declining.append(vuln_type)
        
        return sorted(declining, key=lambda x: historical_counts[x], reverse=True)
    
    def _analyze_severity_trends(self, vulnerabilities: List[Dict[str, Any]], 
                                time_period_days: int) -> Dict[str, float]:
        """Analyze trends in vulnerability severity."""
        
        # Split into time periods
        mid_point = datetime.now() - timedelta(days=time_period_days // 2)
        
        recent_severities = [v['severity'] for v in vulnerabilities 
                           if datetime.fromisoformat(v['detected_at']) >= mid_point]
        historical_severities = [v['severity'] for v in vulnerabilities 
                               if datetime.fromisoformat(v['detected_at']) < mid_point]
        
        severity_trends = {}
        
        for severity in ['critical', 'high', 'medium', 'low']:
            recent_pct = (recent_severities.count(severity) / 
                         max(len(recent_severities), 1)) * 100
            historical_pct = (historical_severities.count(severity) / 
                            max(len(historical_severities), 1)) * 100
            
            # Calculate percentage point change
            severity_trends[severity] = recent_pct - historical_pct
        
        return severity_trends
    
    def _analyze_confidence_trends(self, vulnerabilities: List[Dict[str, Any]], 
                                  time_period_days: int) -> Dict[str, float]:
        """Analyze trends in confidence scores."""
        
        # Group by vulnerability type
        confidence_trends = {}
        
        for vuln_type in set(v['vulnerability_type'] for v in vulnerabilities):
            type_vulns = [v for v in vulnerabilities 
                         if v['vulnerability_type'] == vuln_type]
            
            if len(type_vulns) < 5:  # Need minimum samples
                continue
            
            # Sort by detection time
            type_vulns.sort(key=lambda x: x['detected_at'])
            
            # Calculate trend in confidence scores
            scores = [v['confidence_score'] for v in type_vulns]
            
            if len(scores) > 1:
                # Simple linear trend
                x = np.arange(len(scores))
                slope = np.polyfit(x, scores, 1)[0]
                confidence_trends[vuln_type] = slope
        
        return confidence_trends
    
    def _store_trend_snapshots(self, trends: List[VulnerabilityTrend]):
        """Store trend snapshots for historical analysis."""
        
        for trend in trends:
            self.db.store_trend_snapshot(
                trend.vulnerability_type,
                trend.total_occurrences,
                trend.confidence_trend,
                trend.severity_distribution
            )
    
    def _create_empty_analysis(self, time_period_days: int) -> TrendAnalysis:
        """Create empty analysis when no data available."""
        
        return TrendAnalysis(
            analysis_date=datetime.now().isoformat(),
            time_period=f"{time_period_days} days",
            total_vulnerabilities=0,
            trending_up=[],
            trending_down=[],
            stable_trends=[],
            emerging_threats=[],
            declining_threats=[],
            severity_trends={},
            confidence_trends={}
        )
    
    def generate_trend_report(self, analysis: TrendAnalysis) -> Dict[str, Any]:
        """Generate comprehensive trend report."""
        
        report = {
            "executive_summary": {
                "analysis_period": analysis.time_period,
                "total_vulnerabilities": analysis.total_vulnerabilities,
                "trending_up_count": len(analysis.trending_up),
                "trending_down_count": len(analysis.trending_down),
                "emerging_threats_count": len(analysis.emerging_threats),
                "key_insights": self._generate_key_insights(analysis)
            },
            "trending_vulnerabilities": {
                "increasing": [asdict(t) for t in analysis.trending_up[:10]],
                "decreasing": [asdict(t) for t in analysis.trending_down[:10]],
                "stable": [asdict(t) for t in analysis.stable_trends[:5]]
            },
            "threat_intelligence": {
                "emerging_threats": analysis.emerging_threats,
                "declining_threats": analysis.declining_threats,
                "threat_categories": self._categorize_threats(analysis)
            },
            "severity_analysis": {
                "severity_trends": analysis.severity_trends,
                "severity_insights": self._analyze_severity_insights(analysis.severity_trends)
            },
            "confidence_analysis": {
                "confidence_trends": analysis.confidence_trends,
                "detection_quality": self._assess_detection_quality(analysis.confidence_trends)
            },
            "recommendations": self._generate_recommendations(analysis)
        }
        
        return report
    
    def _generate_key_insights(self, analysis: TrendAnalysis) -> List[str]:
        """Generate key insights from trend analysis."""
        
        insights = []
        
        if analysis.emerging_threats:
            insights.append(f"🚨 {len(analysis.emerging_threats)} emerging threat patterns detected")
        
        if analysis.trending_up:
            top_increasing = analysis.trending_up[0]
            insights.append(f"📈 {top_increasing.vulnerability_type} showing strongest upward trend")
        
        if analysis.declining_threats:
            insights.append(f"📉 {len(analysis.declining_threats)} threat types declining")
        
        # Severity insights
        if analysis.severity_trends.get('critical', 0) > 5:
            insights.append("⚠️ Critical vulnerabilities increasing significantly")
        
        return insights
    
    def _categorize_threats(self, analysis: TrendAnalysis) -> Dict[str, List[str]]:
        """Categorize threats by vulnerability category."""
        
        categorized = defaultdict(list)
        
        all_threats = (analysis.emerging_threats + 
                      [t.vulnerability_type for t in analysis.trending_up])
        
        for threat in all_threats:
            for category, vuln_types in self.vulnerability_categories.items():
                if any(vtype in threat.lower() for vtype in vuln_types):
                    categorized[category].append(threat)
                    break
            else:
                categorized["other"].append(threat)
        
        return dict(categorized)
    
    def _analyze_severity_insights(self, severity_trends: Dict[str, float]) -> List[str]:
        """Analyze severity trend insights."""
        
        insights = []
        
        for severity, change in severity_trends.items():
            if abs(change) > 5:  # More than 5 percentage point change
                direction = "increasing" if change > 0 else "decreasing"
                insights.append(f"{severity.title()} severity vulnerabilities {direction} by {abs(change):.1f}%")
        
        return insights
    
    def _assess_detection_quality(self, confidence_trends: Dict[str, float]) -> Dict[str, Any]:
        """Assess detection quality based on confidence trends."""
        
        if not confidence_trends:
            return {"assessment": "insufficient_data"}
        
        avg_trend = statistics.mean(confidence_trends.values())
        improving_count = sum(1 for trend in confidence_trends.values() if trend > 0.05)
        declining_count = sum(1 for trend in confidence_trends.values() if trend < -0.05)
        
        return {
            "overall_trend": "improving" if avg_trend > 0.02 else "declining" if avg_trend < -0.02 else "stable",
            "improving_types": improving_count,
            "declining_types": declining_count,
            "average_change": avg_trend
        }
    
    def _generate_recommendations(self, analysis: TrendAnalysis) -> List[str]:
        """Generate actionable recommendations."""
        
        recommendations = []
        
        # Emerging threats recommendations
        if analysis.emerging_threats:
            recommendations.append(
                f"🎯 Priority: Investigate {analysis.emerging_threats[0]} - new emerging threat pattern"
            )
        
        # High-trend vulnerabilities
        if analysis.trending_up:
            top_trend = analysis.trending_up[0]
            recommendations.append(
                f"📊 Focus: {top_trend.vulnerability_type} showing {top_trend.change_rate:.1%} increase"
            )
        
        # Severity-based recommendations
        if analysis.severity_trends.get('critical', 0) > 10:
            recommendations.append("🚨 Critical: Immediate review of critical vulnerability detection")
        
        # Detection quality recommendations
        declining_confidence = [vtype for vtype, trend in analysis.confidence_trends.items() 
                              if trend < -0.1]
        if declining_confidence:
            recommendations.append(
                f"🔧 Improve: Detection accuracy for {', '.join(declining_confidence[:3])}"
            )
        
        return recommendations

# Global vulnerability trend analyzer
vulnerability_analyzer = VulnerabilityTrendAnalyzer()

def analyze_vulnerability_trends(time_period_days: int = 30) -> Dict[str, Any]:
    """Global function for vulnerability trend analysis."""
    analysis = vulnerability_analyzer.analyze_vulnerability_trends(time_period_days)
    return vulnerability_analyzer.generate_trend_report(analysis)

def store_vulnerability_finding(apk_name: str, vulnerability_data: Dict[str, Any]) -> bool:
    """Global function to store vulnerability findings for trend analysis."""
    return vulnerability_analyzer.db.store_vulnerability(apk_name, vulnerability_data) 