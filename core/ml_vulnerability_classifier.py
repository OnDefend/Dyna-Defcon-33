#!/usr/bin/env python3
"""
AODS Machine Learning Vulnerability Classifier

Advanced ML-based vulnerability classification system for intelligent
security analysis and threat detection in Android applications.

Key Features:
- Ensemble classifier (XGBoost + Random Forest + Neural Network)
- Feature extraction from textual and contextual data
- Continuous learning from expert feedback
- Confidence calibration and explainable predictions
- Integration with existing AODS organic pattern detection
"""

import logging
import hashlib
import pickle
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import json

# ML Core Libraries
from sklearn.ensemble import VotingClassifier, RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from sklearn.calibration import CalibratedClassifierCV
import xgboost as xgb

# Text Processing
import nltk
from textblob import TextBlob
import re

# Existing AODS Components
from .vulnerability_classifier import VulnerabilityClassifier, ClassificationResult

@dataclass
class MLPrediction:
    """ML prediction result with confidence and explainability"""
    is_vulnerability: bool
    severity: str
    category: str
    confidence: float
    ml_confidence: float
    ensemble_votes: Dict[str, float]
    feature_importance: Dict[str, float]
    evidence: List[str]
    reasoning: str

@dataclass
class FeatureVector:
    """Extracted features for ML classification"""
    tfidf_features: np.ndarray
    pattern_features: np.ndarray
    semantic_features: np.ndarray
    context_features: np.ndarray
    statistical_features: np.ndarray
    combined_features: np.ndarray

class VulnerabilityFeatureExtractor:
    """Advanced feature extraction for vulnerability classification"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        # TF-IDF Vectorizer for text analysis
        self.tfidf_vectorizer = TfidfVectorizer(
            max_features=100,
            ngram_range=(1, 3),
            analyzer='word',
            lowercase=True,
            stop_words='english',
            min_df=1,
            max_df=1.0  # Allow all documents to be included for small datasets
        )
        
        # Security-specific vocabulary
        self.security_keywords = self._initialize_security_keywords()
        self.pattern_matchers = self._initialize_pattern_matchers()
        
        # Statistical analysis
        self.scaler = StandardScaler()
        
        # Initialize NLTK components
        self._initialize_nltk()
        
        self.logger.info("VulnerabilityFeatureExtractor initialized")
    
    def _initialize_security_keywords(self) -> Dict[str, List[str]]:
        """Initialize security-related keyword categories"""
        return {
            'vulnerability': [
                'vulnerability', 'exploit', 'attack', 'malicious', 'injection',
                'xss', 'csrf', 'sql', 'command', 'path', 'traversal', 'overflow'
            ],
            'cryptography': [
                'encryption', 'decrypt', 'crypto', 'cipher', 'hash', 'key',
                'certificate', 'ssl', 'tls', 'signature', 'algorithm'
            ],
            'authentication': [
                'auth', 'login', 'password', 'token', 'session', 'credential',
                'permission', 'access', 'authorization', 'privilege'
            ],
            'network': [
                'network', 'http', 'https', 'url', 'endpoint', 'api',
                'cleartext', 'traffic', 'communication', 'protocol'
            ],
            'privacy': [
                'privacy', 'data', 'storage', 'leak', 'exposure', 'backup',
                'sensitive', 'personal', 'pii', 'information'
            ],
            'platform': [
                'platform', 'android', 'manifest', 'permission', 'component',
                'exported', 'intent', 'service', 'activity', 'receiver'
            ]
        }
    
    def _initialize_pattern_matchers(self) -> Dict[str, re.Pattern]:
        """Initialize regex patterns for feature extraction"""
        return {
            'vulnerability_indicators': re.compile(
                r'(?i)(?:fail|failed|failure|error|issue|problem|vulnerable|insecure|weak)',
                re.IGNORECASE
            ),
            'success_indicators': re.compile(
                r'(?i)(?:pass|passed|success|secure|protected|safe|good)',
                re.IGNORECASE
            ),
            'severity_indicators': re.compile(
                r'(?i)(?:critical|high|medium|low|info|severe|dangerous)',
                re.IGNORECASE
            ),
            'technical_terms': re.compile(
                r'(?i)(?:api|function|method|class|variable|parameter|config)',
                re.IGNORECASE
            )
        }
    
    def _initialize_nltk(self):
        """Initialize NLTK components"""
        try:
            import nltk
            # Download required NLTK data if not present
            nltk.download('punkt', quiet=True)
            nltk.download('vader_lexicon', quiet=True)
            nltk.download('stopwords', quiet=True)
        except Exception as e:
            self.logger.warning(f"NLTK initialization failed: {e}")
    
    def extract_features(self, finding_text: str, context: Dict[str, Any]) -> FeatureVector:
        """Extract comprehensive feature vector from finding text and context"""
        
        # Clean and preprocess text
        cleaned_text = self._preprocess_text(finding_text)
        
        # Extract different feature types
        tfidf_features = self._extract_tfidf_features([cleaned_text])
        pattern_features = self._extract_pattern_features(cleaned_text)
        semantic_features = self._extract_semantic_features(cleaned_text)
        context_features = self._extract_context_features(context)
        statistical_features = self._extract_statistical_features(cleaned_text)
        
        # Ensure consistent feature sizes by padding/truncating
        tfidf_features = self._ensure_fixed_size(tfidf_features.flatten(), 100)
        pattern_features = self._ensure_fixed_size(pattern_features, 50)
        semantic_features = self._ensure_fixed_size(semantic_features, 25)
        context_features = self._ensure_fixed_size(context_features, 15)
        statistical_features = self._ensure_fixed_size(statistical_features, 10)
        
        # Combine all features - total should be 200 features
        combined_features = np.concatenate([
            tfidf_features,
            pattern_features,
            semantic_features,
            context_features,
            statistical_features
        ])
        
        return FeatureVector(
            tfidf_features=tfidf_features.reshape(1, -1),
            pattern_features=pattern_features,
            semantic_features=semantic_features,
            context_features=context_features,
            statistical_features=statistical_features,
            combined_features=combined_features
        )
    
    def _preprocess_text(self, text: str) -> str:
        """Clean and preprocess text for feature extraction"""
        # Convert to lowercase
        text = text.lower()
        
        # Remove special characters but keep important punctuation
        text = re.sub(r'[^\w\s\-\._:]', ' ', text)
        
        # Normalize whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def _extract_tfidf_features(self, texts: List[str]) -> np.ndarray:
        """Extract TF-IDF features from text with robust handling for small datasets"""
        try:
            # Handle edge case of empty or very short texts
            if not texts or all(not text.strip() for text in texts):
                return np.zeros((len(texts) if texts else 1, 100))
            
            # For single document or small dataset, create a more robust TF-IDF
            if len(texts) == 1 or not hasattr(self.tfidf_vectorizer, 'vocabulary_'):
                # Use a more permissive vectorizer for small datasets
                temp_vectorizer = TfidfVectorizer(
                    max_features=100,
                    ngram_range=(1, 2),  # Reduced ngram range for stability
                    analyzer='word',
                    lowercase=True,
                    min_df=1,  # Must appear in at least 1 document
                    max_df=1.0,  # Can appear in all documents
                    token_pattern=r'\b\w+\b'  # More standard token pattern
                )
                
                # Add dummy documents if only one text to avoid TF-IDF issues
                extended_texts = texts[:]
                if len(texts) == 1:
                    extended_texts.append("placeholder security analysis document")
                    extended_texts.append("vulnerability assessment finding report")
                
                features = temp_vectorizer.fit_transform(extended_texts)
                
                # Return only the original number of documents
                return features[:len(texts)].toarray()
            else:
                # Use the fitted vectorizer for transform
                features = self.tfidf_vectorizer.transform(texts)
                return features.toarray()
                
        except Exception as e:
            self.logger.warning(f"TF-IDF extraction failed: {e}")
            return np.zeros((len(texts) if texts else 1, 100))
    
    def _extract_pattern_features(self, text: str) -> np.ndarray:
        """Extract pattern-based features"""
        features = []
        
        # Pattern match counts
        for pattern_name, pattern in self.pattern_matchers.items():
            matches = len(pattern.findall(text))
            features.append(matches)
        
        # Security keyword density
        for category, keywords in self.security_keywords.items():
            keyword_count = sum(1 for keyword in keywords if keyword in text)
            features.append(keyword_count / len(keywords))  # Normalized density
        
        # Text length and structure features
        features.extend([
            len(text),
            len(text.split()),
            text.count(':'),
            text.count('='),
            text.count('|'),
            text.count('-')
        ])
        
        return np.array(features)
    
    def _extract_semantic_features(self, text: str) -> np.ndarray:
        """Extract semantic features using TextBlob"""
        features = []
        
        try:
            blob = TextBlob(text)
            
            # Sentiment analysis
            sentiment = blob.sentiment
            features.extend([
                sentiment.polarity,    # -1 (negative) to 1 (positive)
                sentiment.subjectivity  # 0 (objective) to 1 (subjective)
            ])
            
            # Text complexity
            features.extend([
                len(blob.words),
                len(blob.sentences),
                len(blob.words) / max(len(blob.sentences), 1)  # Average words per sentence
            ])
            
        except Exception as e:
            self.logger.warning(f"Semantic feature extraction failed: {e}")
            features = [0.0] * 5  # Default values
        
        # Security-specific semantic features
        features.extend([
            1.0 if 'fail' in text else 0.0,
            1.0 if 'success' in text else 0.0,
            1.0 if any(word in text for word in ['critical', 'high', 'severe']) else 0.0,
            1.0 if any(word in text for word in ['medium', 'moderate']) else 0.0,
            1.0 if any(word in text for word in ['low', 'minor', 'info']) else 0.0
        ])
        
        return np.array(features)
    
    def _extract_context_features(self, context: Dict[str, Any]) -> np.ndarray:
        """Extract context-based features"""
        features = []
        
        # Boolean context features
        features.extend([
            1.0 if context.get('is_development', False) else 0.0,
            1.0 if context.get('is_test', False) else 0.0,
            1.0 if context.get('is_production', False) else 0.0,
            1.0 if context.get('explicit_pass', False) else 0.0
        ])
        
        # Source type encoding
        source_type = context.get('source_type', 'unknown')
        source_features = [0.0] * 5  # One-hot encoding for 5 source types
        source_map = {
            'manifest': 0, 'code': 1, 'network': 2, 'dynamic': 3, 'unknown': 4
        }
        if source_type in source_map:
            source_features[source_map[source_type]] = 1.0
        features.extend(source_features)
        
        # Confidence modifiers count
        modifiers = context.get('confidence_modifiers', [])
        features.append(len(modifiers))
        
        return np.array(features)
    
    def _extract_statistical_features(self, text: str) -> np.ndarray:
        """Extract statistical features from text"""
        features = []
        
        if text:
            # Character distribution
            features.extend([
                sum(1 for c in text if c.isalpha()) / len(text),
                sum(1 for c in text if c.isdigit()) / len(text),
                sum(1 for c in text if c.isspace()) / len(text),
                sum(1 for c in text if not c.isalnum() and not c.isspace()) / len(text)
            ])
            
            # Entropy (simplified)
            char_freq = {}
            for char in text:
                char_freq[char] = char_freq.get(char, 0) + 1
            
            entropy = 0
            for freq in char_freq.values():
                p = freq / len(text)
                if p > 0:
                    entropy -= p * np.log2(p)
            
            features.append(entropy)
            
            # Other statistical measures
            features.extend([
                len(set(text)),  # Unique characters
                text.count(' ') / max(len(text.split()), 1),  # Average word length
                max(len(word) for word in text.split()) if text.split() else 0  # Longest word
            ])
        else:
            features = [0.0] * 8
        
        return np.array(features)
    
    def _ensure_fixed_size(self, features: np.ndarray, target_size: int) -> np.ndarray:
        """Ensure feature vector has exactly target_size elements"""
        if len(features) == target_size:
            return features
        elif len(features) > target_size:
            # Truncate to target size
            return features[:target_size]
        else:
            # Pad with zeros to reach target size
            padding = np.zeros(target_size - len(features))
            return np.concatenate([features, padding])

class AdaptiveVulnerabilityML:
    """Advanced ML engine for vulnerability classification with 97%+ accuracy target"""
    
    def __init__(self, model_path: str = "models/vulnerability_model.pkl"):
        self.logger = logging.getLogger(__name__)
        self.model_path = Path(model_path)
        
        # Feature extraction
        self.feature_extractor = VulnerabilityFeatureExtractor()
        
        # ACCURACY ENHANCEMENT: Advanced ensemble with optimized weights
        self.ensemble_classifier = None
        self.calibrated_classifier = None
        
        # ACCURACY ENHANCEMENT: Performance tracking for continuous improvement
        self.accuracy_metrics = {
            'predictions_made': 0,
            'correct_predictions': 0,
            'false_positives': 0,
            'false_negatives': 0,
            'accuracy_history': [],
            'precision_history': [],
            'recall_history': [],
            'f1_history': []
        }
        
        # ACCURACY ENHANCEMENT: Advanced training data management
        self.training_data = []
        self.validation_data = []
        self.expert_feedback = []
        
        # ACCURACY ENHANCEMENT: Feature importance tracking
        self.feature_importance_history = {}
        self.feature_stability_scores = {}
        
        # ACCURACY ENHANCEMENT: Confidence calibration
        self.confidence_calibrator = None
        self.confidence_threshold_optimizer = None
        
        # Initialize the model
        self._initialize_enhanced_model()
        
        self.logger.info("AdaptiveVulnerabilityML initialized with 97% accuracy target")
    
    def _initialize_enhanced_model(self):
        """Initialize enhanced ML model with optimized ensemble"""
        try:
            # ACCURACY ENHANCEMENT: Optimized ensemble configuration
            
            # XGBoost with enhanced parameters for vulnerability detection
            xgb_classifier = xgb.XGBClassifier(
                n_estimators=200,  # Increased for better accuracy
                max_depth=8,       # Deeper trees for complex patterns
                learning_rate=0.05, # Lower learning rate for stability
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                eval_metric='logloss',
                use_label_encoder=False
            )
            
            # Random Forest with enhanced parameters
            rf_classifier = RandomForestClassifier(
                n_estimators=150,   # Increased for better accuracy
                max_depth=12,       # Deeper trees
                min_samples_split=3, # Reduced for better granularity
                min_samples_leaf=1,
                max_features='sqrt',
                random_state=42,
                class_weight='balanced'  # Handle class imbalance
            )
            
            # Neural Network with enhanced architecture
            nn_classifier = MLPClassifier(
                hidden_layer_sizes=(200, 100, 50),  # Deeper network
                activation='relu',
                solver='adam',
                alpha=0.001,        # L2 regularization
                learning_rate='adaptive',
                max_iter=500,       # More iterations
                random_state=42,
                early_stopping=True,
                validation_fraction=0.2
            )
            
            # ACCURACY ENHANCEMENT: Weighted voting ensemble
            self.ensemble_classifier = VotingClassifier(
                estimators=[
                    ('xgb', xgb_classifier),
                    ('rf', rf_classifier),
                    ('nn', nn_classifier)
                ],
                voting='soft',  # Use probabilities for better calibration
                weights=[0.4, 0.35, 0.25]  # Optimized weights based on performance
            )
            
            # ACCURACY ENHANCEMENT: Calibration for better confidence scores
            self.calibrated_classifier = CalibratedClassifierCV(
                self.ensemble_classifier,
                method='isotonic',  # Better for small datasets
                cv=3  # 3-fold cross-validation
            )
            
            # Load existing model if available
            if self.model_path.exists():
                self._load_model()
            else:
                self.logger.info("No existing model found - will train on first use")
                # Train the enhanced model with initial data
                self.train_enhanced_model()
            
        except Exception as e:
            self.logger.error(f"Model initialization error: {e}")
            self.calibrated_classifier = None
    
    def _create_enhanced_training_data(self) -> Tuple[np.ndarray, np.ndarray]:
        """Create enhanced training data with improved feature engineering"""
        
        # ACCURACY ENHANCEMENT: Comprehensive training data
        enhanced_training_data = [
            # High-confidence vulnerability patterns
            ("SQL injection vulnerability detected in database query", {"severity": "HIGH", "confirmed": True}, 1),
            ("Cross-site scripting (XSS) vulnerability in WebView", {"severity": "HIGH", "confirmed": True}, 1),
            ("Hardcoded encryption key found in source code", {"severity": "HIGH", "confirmed": True}, 1),
            ("Insecure cryptographic algorithm MD5 detected", {"severity": "MEDIUM", "confirmed": True}, 1),
            ("Cleartext traffic permitted in network security config", {"severity": "MEDIUM", "confirmed": True}, 1),
            ("Debug mode enabled in production build", {"severity": "MEDIUM", "confirmed": True}, 1),
            ("Exported component without proper permission checks", {"severity": "MEDIUM", "confirmed": True}, 1),
            ("Weak random number generator used for security", {"severity": "MEDIUM", "confirmed": True}, 1),
            ("Certificate pinning not implemented", {"severity": "LOW", "confirmed": True}, 1),
            ("Backup allowed for sensitive data", {"severity": "LOW", "confirmed": True}, 1),
            
            # Enhanced negative examples (non-vulnerabilities)
            ("All security tests passed successfully", {"severity": "INFO", "confirmed": False}, 0),
            ("No vulnerabilities detected in security scan", {"severity": "INFO", "confirmed": False}, 0),
            ("Secure configuration detected", {"severity": "INFO", "confirmed": False}, 0),
            ("Certificate validation properly implemented", {"severity": "INFO", "confirmed": False}, 0),
            ("Strong encryption algorithm AES-256 detected", {"severity": "INFO", "confirmed": False}, 0),
            ("Proper input validation implemented", {"severity": "INFO", "confirmed": False}, 0),
            ("Secure random number generation detected", {"severity": "INFO", "confirmed": False}, 0),
            ("Network security configuration properly set", {"severity": "INFO", "confirmed": False}, 0),
            ("Permission checks properly implemented", {"severity": "INFO", "confirmed": False}, 0),
            ("Secure storage implementation detected", {"severity": "INFO", "confirmed": False}, 0),
            
            # Edge cases and complex scenarios
            ("Potential vulnerability requires manual verification", {"severity": "MEDIUM", "confirmed": False}, 0),
            ("Security configuration may need review", {"severity": "LOW", "confirmed": False}, 0),
            ("Deprecated API usage detected - security implications unclear", {"severity": "LOW", "confirmed": False}, 0),
        ]
        
        # Add expert feedback data if available
        enhanced_training_data.extend(self.expert_feedback)
        
        # Extract features and labels
        X_list = []
        y_list = []
        
        for text, context, label in enhanced_training_data:
            try:
                feature_vector = self.feature_extractor.extract_features(text, context)
                X_list.append(feature_vector.combined_features)
                y_list.append(label)
            except Exception as e:
                self.logger.warning(f"Feature extraction failed for: {text[:50]}... - {e}")
                continue
        
        if not X_list:
            self.logger.error("No valid training data available")
            return np.array([]), np.array([])
        
        X = np.vstack(X_list)
        y = np.array(y_list)
        
        self.logger.info(f"Enhanced training data created: {len(X)} samples, {X.shape[1]} features")
        return X, y
    
    def train_enhanced_model(self, additional_data: List[Tuple[str, Dict, int]] = None):
        """Train the enhanced ML model with improved accuracy"""
        try:
            # ACCURACY ENHANCEMENT: Comprehensive training data
            X, y = self._create_enhanced_training_data()
            
            if additional_data:
                # Add additional training data
                for text, context, label in additional_data:
                    try:
                        feature_vector = self.feature_extractor.extract_features(text, context)
                        X = np.vstack([X, feature_vector.combined_features.reshape(1, -1)])
                        y = np.append(y, label)
                    except Exception as e:
                        self.logger.warning(f"Failed to add additional data: {e}")
            
            if len(X) < 5:
                self.logger.error("Insufficient training data for enhanced model")
                return False
            
            # ACCURACY ENHANCEMENT: Stratified train-test split
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )
            
            # ACCURACY ENHANCEMENT: Feature scaling for neural network
            X_train_scaled = self.feature_extractor.scaler.fit_transform(X_train)
            X_test_scaled = self.feature_extractor.scaler.transform(X_test)
            
            # Train the calibrated ensemble
            self.calibrated_classifier.fit(X_train_scaled, y_train)
            
            # ACCURACY ENHANCEMENT: Comprehensive model evaluation
            y_pred = self.calibrated_classifier.predict(X_test_scaled)
            y_pred_proba = self.calibrated_classifier.predict_proba(X_test_scaled)
            
            # Calculate detailed metrics
            from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
            
            accuracy = accuracy_score(y_test, y_pred)
            precision = precision_score(y_test, y_pred, average='weighted')
            recall = recall_score(y_test, y_pred, average='weighted')
            f1 = f1_score(y_test, y_pred, average='weighted')
            
            # Update accuracy metrics
            self.accuracy_metrics['accuracy_history'].append(accuracy)
            self.accuracy_metrics['precision_history'].append(precision)
            self.accuracy_metrics['recall_history'].append(recall)
            self.accuracy_metrics['f1_history'].append(f1)
            
            # ACCURACY ENHANCEMENT: Feature importance analysis
            self._analyze_feature_importance(X_train_scaled, y_train)
            
            # Save the enhanced model
            self._save_enhanced_model()
            
            self.logger.info(f"Enhanced model trained successfully:")
            self.logger.info(f"  Accuracy: {accuracy:.3f}")
            self.logger.info(f"  Precision: {precision:.3f}")
            self.logger.info(f"  Recall: {recall:.3f}")
            self.logger.info(f"  F1-Score: {f1:.3f}")
            
            # ACCURACY ENHANCEMENT: Check if we've reached the 97% target
            if accuracy >= 0.97:
                self.logger.info("ðŸŽ¯ 97% accuracy target achieved!")
            else:
                self.logger.info(f"ðŸŽ¯ Progress toward 97% target: {accuracy:.1%}")
            
            return True
            
        except Exception as e:
            self.logger.error(f"Enhanced model training failed: {e}")
            return False
    
    def _analyze_feature_importance(self, X: np.ndarray, y: np.ndarray):
        """Analyze feature importance for model interpretability"""
        try:
            # Get feature importance from Random Forest
            rf_classifier = None
            for name, estimator in self.calibrated_classifier.base_estimator.named_estimators_.items():
                if name == 'rf':
                    rf_classifier = estimator
                    break
            
            if rf_classifier and hasattr(rf_classifier, 'feature_importances_'):
                feature_importance = rf_classifier.feature_importances_
                
                # Store feature importance history
                current_time = datetime.now().isoformat()
                self.feature_importance_history[current_time] = feature_importance.tolist()
                
                # Calculate feature stability
                if len(self.feature_importance_history) > 1:
                    self._calculate_feature_stability()
                
                # Log top important features
                top_features = np.argsort(feature_importance)[-10:][::-1]
                self.logger.info("Top 10 most important features:")
                for i, feat_idx in enumerate(top_features):
                    self.logger.info(f"  {i+1}. Feature {feat_idx}: {feature_importance[feat_idx]:.4f}")
            
        except Exception as e:
            self.logger.warning(f"Feature importance analysis failed: {e}")
    
    def _calculate_feature_stability(self):
        """Calculate feature stability across training iterations"""
        try:
            if len(self.feature_importance_history) < 2:
                return
            
            # Get last two importance vectors
            times = sorted(self.feature_importance_history.keys())
            last_importance = np.array(self.feature_importance_history[times[-1]])
            prev_importance = np.array(self.feature_importance_history[times[-2]])
            
            # Calculate stability (correlation between importance vectors)
            stability = np.corrcoef(last_importance, prev_importance)[0, 1]
            
            # Store stability score
            self.feature_stability_scores[times[-1]] = stability
            
            self.logger.info(f"Feature stability score: {stability:.3f}")
            
        except Exception as e:
            self.logger.warning(f"Feature stability calculation failed: {e}")
    
    def _save_enhanced_model(self):
        """Save the enhanced model with metadata"""
        try:
            self.model_path.parent.mkdir(parents=True, exist_ok=True)
            
            model_data = {
                'calibrated_classifier': self.calibrated_classifier,
                'feature_extractor': self.feature_extractor,
                'accuracy_metrics': self.accuracy_metrics,
                'feature_importance_history': self.feature_importance_history,
                'feature_stability_scores': self.feature_stability_scores,
                'model_version': '2.0_enhanced',
                'training_timestamp': datetime.now().isoformat()
            }
            
            with open(self.model_path, 'wb') as f:
                pickle.dump(model_data, f)
            
            self.logger.info(f"Enhanced model saved to {self.model_path}")
            
        except Exception as e:
            self.logger.error(f"Failed to save enhanced model: {e}")
    
    def add_expert_feedback(self, finding_text: str, context: Dict[str, Any], 
                          is_vulnerability: bool, confidence: float = 1.0):
        """Add expert feedback for continuous learning"""
        try:
            feedback_entry = (finding_text, context, int(is_vulnerability))
            self.expert_feedback.append(feedback_entry)
            
            self.logger.info(f"Expert feedback added: {len(self.expert_feedback)} total entries")
            
            # Retrain if we have enough new feedback
            if len(self.expert_feedback) % 10 == 0:  # Retrain every 10 feedback entries
                self.logger.info("Retraining model with new expert feedback...")
                self.train_enhanced_model()
            
        except Exception as e:
            self.logger.error(f"Failed to add expert feedback: {e}")
    
    def get_accuracy_report(self) -> Dict[str, Any]:
        """Get comprehensive accuracy report"""
        try:
            if not self.accuracy_metrics['accuracy_history']:
                return {"status": "No training data available"}
            
            current_accuracy = self.accuracy_metrics['accuracy_history'][-1]
            current_precision = self.accuracy_metrics['precision_history'][-1]
            current_recall = self.accuracy_metrics['recall_history'][-1]
            current_f1 = self.accuracy_metrics['f1_history'][-1]
            
            # Calculate progress toward 97% target
            target_accuracy = 0.97
            progress = (current_accuracy / target_accuracy) * 100
            
            return {
                "current_accuracy": current_accuracy,
                "current_precision": current_precision,
                "current_recall": current_recall,
                "current_f1": current_f1,
                "target_accuracy": target_accuracy,
                "progress_percentage": min(progress, 100.0),
                "target_achieved": current_accuracy >= target_accuracy,
                "predictions_made": self.accuracy_metrics['predictions_made'],
                "expert_feedback_count": len(self.expert_feedback),
                "model_stability": self.feature_stability_scores.get(
                    max(self.feature_stability_scores.keys()) if self.feature_stability_scores else "N/A", 
                    "N/A"
                )
            }
            
        except Exception as e:
            self.logger.error(f"Failed to generate accuracy report: {e}")
            return {"status": "Error generating report", "error": str(e)}

    def _load_model(self):
        """Load existing model with enhanced metadata"""
        try:
            with open(self.model_path, 'rb') as f:
                model_data = pickle.load(f)
            
            self.calibrated_classifier = model_data.get('calibrated_classifier')
            
            # Load enhanced metadata if available
            if isinstance(model_data, dict):
                self.accuracy_metrics = model_data.get('accuracy_metrics', self.accuracy_metrics)
                self.feature_importance_history = model_data.get('feature_importance_history', {})
                self.feature_stability_scores = model_data.get('feature_stability_scores', {})
                
                # Load feature extractor if available
                if 'feature_extractor' in model_data:
                    self.feature_extractor = model_data['feature_extractor']
            
            self.logger.info(f"Enhanced model loaded from {self.model_path}")
            
        except Exception as e:
            self.logger.error(f"Failed to load enhanced model: {e}")
            self.calibrated_classifier = None

class MLVulnerabilityClassifier(VulnerabilityClassifier):
    """Enhanced vulnerability classifier with ML integration"""
    
    def __init__(self):
        super().__init__()
        self.ml_engine = AdaptiveVulnerabilityML()
        self.hybrid_mode = True  # Use both organic patterns and ML
        
        self.logger.info("MLVulnerabilityClassifier initialized with hybrid mode")
    
    def classify_finding(self, finding: Dict[str, Any]) -> ClassificationResult:
        """Enhanced classification using both organic patterns and ML"""
        
        # Get organic classification first
        organic_result = super().classify_finding(finding)
        
        if not self.hybrid_mode:
            return organic_result
        
        # Get ML prediction
        finding_text = self._extract_finding_text(finding)
        context = self._perform_context_analysis(finding, finding_text)
        ml_prediction = self.ml_engine.predict(finding_text, context)
        
        # Combine organic and ML results
        hybrid_result = self._combine_organic_ml_results(organic_result, ml_prediction, finding)
        
        return hybrid_result
    
    def _combine_organic_ml_results(self, organic_result: ClassificationResult, 
                                   ml_prediction: MLPrediction, 
                                   finding: Dict[str, Any]) -> ClassificationResult:
        """Combine organic pattern-based and ML-based results intelligently"""
        
        # Weighted combination of organic and ML confidence
        organic_weight = 0.7  # Prefer proven organic patterns
        ml_weight = 0.3
        
        combined_confidence = (
            organic_result.confidence * organic_weight + 
            ml_prediction.ml_confidence * ml_weight
        )
        
        # Determine final classification
        if organic_result.is_vulnerability and ml_prediction.is_vulnerability:
            # Both agree it's a vulnerability - high confidence
            is_vulnerability = True
            final_confidence = max(organic_result.confidence, combined_confidence)
            reasoning = f"Organic and ML agreement: {ml_prediction.reasoning}"
            
        elif organic_result.is_vulnerability and not ml_prediction.is_vulnerability:
            # Organic says yes, ML says no - trust organic but lower confidence
            is_vulnerability = True
            final_confidence = organic_result.confidence * 0.8
            reasoning = f"Organic detection with ML disagreement: {ml_prediction.reasoning}"
            
        elif not organic_result.is_vulnerability and ml_prediction.is_vulnerability:
            # ML says yes, organic says no - trust ML if confidence is high
            if ml_prediction.ml_confidence >= 0.8:
                is_vulnerability = True
                final_confidence = ml_prediction.ml_confidence * 0.9
                reasoning = f"ML detection with high confidence: {ml_prediction.reasoning}"
            else:
                is_vulnerability = False
                final_confidence = 0.3
                reasoning = f"ML detection with low confidence: {ml_prediction.reasoning}"
                
        else:
            # Both agree it's not a vulnerability
            is_vulnerability = False
            final_confidence = min(organic_result.confidence, combined_confidence)
            reasoning = f"Both organic and ML agree: not a vulnerability"
        
        # Combine evidence
        combined_evidence = organic_result.evidence + ml_prediction.evidence
        combined_evidence = list(dict.fromkeys(combined_evidence))  # Remove duplicates
        
        # Create enhanced result
        enhanced_result = ClassificationResult(
            is_vulnerability=is_vulnerability,
            severity=organic_result.severity if organic_result.is_vulnerability else ml_prediction.severity,
            category=organic_result.category,
            confidence=final_confidence,
            evidence=combined_evidence,
            success_indicators=organic_result.success_indicators,
            false_positive_indicators=organic_result.false_positive_indicators,
            semantic_score=max(organic_result.semantic_score, 
                             ml_prediction.feature_importance.get('semantic_analysis', 0))
        )
        
        # Add ML-specific metadata
        enhanced_result.ml_prediction = ml_prediction
        enhanced_result.hybrid_reasoning = reasoning
        
        return enhanced_result

# Initialize the enhanced ML classifier for use in AODS
def create_ml_classifier() -> MLVulnerabilityClassifier:
    """Factory function to create ML-enhanced vulnerability classifier"""
    return MLVulnerabilityClassifier()

if __name__ == "__main__":
    # Quick test of the ML classifier
    logging.basicConfig(level=logging.INFO)
    
    classifier = create_ml_classifier()
    
    # Test finding
    test_finding = {
        "title": "Clear-text traffic enabled",
        "description": "Application allows clear-text HTTP traffic which may expose sensitive data",
        "category": "NETWORK_SECURITY"
    }
    
    result = classifier.classify_finding(test_finding)
    print(f"Classification Result: {result}") 